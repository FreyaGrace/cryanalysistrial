{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W-A7-OtL7s-9"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'librosa'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "import pickle\n",
        "import tensorflow as tp\n",
        "from collections import Counter\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47ziMC1A704O"
      },
      "outputs": [],
      "source": [
        "# Define raw audio dictionary\n",
        "raw_audio = {}\n",
        "\n",
        "# Loop through directories and label audio files\n",
        "directories = ['hungry', 'belly_pain', 'burping', 'discomfort', 'tired']\n",
        "for directory in directories:\n",
        "    path = '/content/drive/MyDrive/3rd year projects/Research/Thesis/Data and affecting factors/Data Source/donateacry_corpus_cleaned_and_updated_data/' + directory\n",
        "    for filename in os.listdir(path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            raw_audio[os.path.join(path, filename)] = directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q6AEkNK8EKE"
      },
      "outputs": [],
      "source": [
        "# Define function to extract MFCC features and chop audio\n",
        "def extract_mfcc(audio_file, max_length=100):\n",
        "    audiofile, sr = librosa.load(audio_file)\n",
        "    fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "    if fingerprint.shape[1] < max_length:\n",
        "        pad_width = max_length - fingerprint.shape[1]\n",
        "        fingerprint_padded = np.pad(fingerprint, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        return fingerprint_padded.T\n",
        "    elif fingerprint.shape[1] > max_length:\n",
        "        return fingerprint[:, :max_length].T\n",
        "    else:\n",
        "        return fingerprint.T\n",
        "\n",
        "# Chop audio and extract MFCC features for each track\n",
        "X = []\n",
        "y = []\n",
        "max_length = 100\n",
        "for i, (audio_file, label) in enumerate(raw_audio.items()):\n",
        "    mfcc_features = extract_mfcc(audio_file, max_length=max_length)\n",
        "    X.append(mfcc_features)\n",
        "    y.append(label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eXJ6Pf18Nnf"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Flatten the features and labels\n",
        "X_flat = X.reshape(X.shape[0], -1)\n",
        "y_flat = y\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_flat, y_flat, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cbk_h4P8Wm2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train and evaluate models\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier(n_estimators=25, max_features=5)),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('SVM', SVC()),\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFSjIisU-Bj9",
        "outputId": "47c919ef-bc9c-4fc3-ea77-42d3e8e2fe07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model, Accuracy, Precision, Recall\n",
            "Random Forest: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression: 0.717391304347826, 0.6434694238246731, 0.717391304347826\n",
            "Decision Tree: 0.6847826086956522, 0.6806534795665231, 0.6847826086956522\n",
            "SVM: 0.7934782608695652, 0.6296077504725898, 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"Model, Accuracy, Precision, Recall\")\n",
        "for model_name, model in models:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    print(f\"{model_name}: {accuracy}, {precision}, {recall}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdH0N-idBi08",
        "outputId": "705c7a0a-b8ea-4b5f-f8c9-2f452660490c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(364, 2000)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-BdnDwr_c1N",
        "outputId": "a2719b9f-6cf7-4757-a3ce-1cd3bf01311b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 7s 178ms/step - loss: 1.1529 - accuracy: 0.6014 - val_loss: 0.6081 - val_accuracy: 0.8630\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 121ms/step - loss: 0.6935 - accuracy: 0.8454 - val_loss: 0.6093 - val_accuracy: 0.8630\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 116ms/step - loss: 0.6518 - accuracy: 0.8454 - val_loss: 0.6019 - val_accuracy: 0.8630\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 117ms/step - loss: 0.6518 - accuracy: 0.8454 - val_loss: 0.5967 - val_accuracy: 0.8630\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 122ms/step - loss: 0.6063 - accuracy: 0.8454 - val_loss: 0.5909 - val_accuracy: 0.8630\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 2s 158ms/step - loss: 0.6113 - accuracy: 0.8454 - val_loss: 0.5849 - val_accuracy: 0.8630\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 2s 229ms/step - loss: 0.6290 - accuracy: 0.8454 - val_loss: 0.5843 - val_accuracy: 0.8630\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 2s 167ms/step - loss: 0.5955 - accuracy: 0.8454 - val_loss: 0.5861 - val_accuracy: 0.8630\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.6145 - accuracy: 0.8488 - val_loss: 0.5871 - val_accuracy: 0.8630\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 120ms/step - loss: 0.5809 - accuracy: 0.8454 - val_loss: 0.5831 - val_accuracy: 0.8630\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.8745 - accuracy: 0.7935\n",
            "Accuracy: 0.79347825050354\n",
            "3/3 [==============================] - 1s 44ms/step\n",
            "Precision: 0.6296077504725898\n",
            "Recall: 0.7934782608695652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Reshape data for LSTM input\n",
        "n_samples, n_features = X_train.shape[0], X_train.shape[1] // 100\n",
        "n_timesteps = 100\n",
        "X_train_lstm = X_train.reshape((n_samples, 100, 20))\n",
        "n_samples_test = X_test.shape[0]\n",
        "X_test_lstm = X_test.reshape((n_samples_test, n_timesteps, n_features))\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Define LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(units=128, input_shape=(n_timesteps, n_features)),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=len(np.unique(y_train_encoded)), activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "# Compile LSTM model\n",
        "lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train LSTM model\n",
        "lstm_model.fit(X_train_lstm, y_train_encoded, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate LSTM model\n",
        "_, accuracy = lstm_model.evaluate(X_test_lstm, y_test_encoded)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "# Predict probabilities for the test dataset using the trained LSTM model\n",
        "predicted_probabilities = lstm_model.predict(X_test_lstm)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test_encoded, predicted_labels, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4Ll8k9I0NzE",
        "outputId": "2643baa9-190d-49bf-fd2e-7ae05549ed23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lstm_audio_model.joblib']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(lstm_model, \"lstm_audio_model.joblib\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhf5-K372ez0"
      },
      "outputs": [],
      "source": [
        "def pickle_model(model, modelname):\n",
        "    directory = 'models'\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    with open(os.path.join(directory, str(modelname) + '.pkl'), 'wb') as f:\n",
        "        return pickle.dump(model, f)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "pickle_model(model, \"myRandomForest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJC2hBXJogh8"
      },
      "outputs": [],
      "source": [
        "def getModel(pickle_path):\n",
        "  with open(pickle_path, 'rb') as f:\n",
        "        return pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_yqM-jEoXn4"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "model_path = \"models/myRandomForest.pkl\"  # Replace with your model path\n",
        "with open(model_path, \"rb\") as f:\n",
        "    model = joblib.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypgf53c-1zGb",
        "outputId": "85b54901-d73a-4338-ec9a-edac677c9132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pur_4ZQw8kT2",
        "outputId": "85af8245-729c-4ab2-fbe6-c13fb80c82f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Audio chopped successfully!\n"
          ]
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "from pydub import AudioSegment\n",
        "import wave\n",
        "import math\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "# Define the function to chop the audio\n",
        "def chop_new_audio(audio_data, folder):\n",
        "    os.makedirs(folder, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    audio = wave.open(audio_data, 'rb')\n",
        "    frame_rate = audio.getframerate()\n",
        "    n_frames = audio.getnframes()\n",
        "    window_size = 2 * frame_rate\n",
        "    num_secs = int(math.ceil(n_frames / frame_rate))\n",
        "    last_number_frames = 0\n",
        "    for i in range(num_secs):\n",
        "        shortfilename = str(uuid.uuid4())  # Generate a unique filename\n",
        "        snippetfilename = f\"{folder}/{shortfilename}snippet{i+1}.wav\"\n",
        "        snippet = wave.open(snippetfilename, 'wb')\n",
        "        snippet.setnchannels(2)\n",
        "        snippet.setsampwidth(audio.getsampwidth())\n",
        "        snippet.setframerate(frame_rate)\n",
        "        snippet.setnframes(audio.getnframes())\n",
        "        snippet.writeframes(audio.readframes(window_size))\n",
        "        audio.setpos(audio.tell() - 1 * frame_rate)\n",
        "\n",
        "         # Check if the frame size of the snippet matches the previous snippets\n",
        "        if last_number_frames < 1:\n",
        "            last_number_frames = snippet.getnframes()\n",
        "        elif snippet.getnframes() != last_number_frames:\n",
        "            os.rename(snippetfilename, f\"{snippetfilename}.bak\")\n",
        "        snippet.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example of reading audio data from a file-like object (e.g., uploaded file)\n",
        "    with open('hungry baby.mp3', 'rb') as f:\n",
        "        mp3_data = f.read()\n",
        "\n",
        "    audio = AudioSegment.from_mp3(BytesIO(mp3_data))\n",
        "    wav_data = BytesIO()\n",
        "    audio.export(wav_data, format=\"wav\")\n",
        "    wav_data.seek(0)\n",
        "\n",
        "    folder_name = \"samples\"\n",
        "    chop_new_audio(wav_data, folder_name)\n",
        "    print(\"Audio chopped successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc22mK_i8r4m",
        "outputId": "894752d7-31e3-490f-8eae-f7b90aef0e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('discomfort', 35), ('tired', 27), ('hungry', 1)]\n",
            "[('discomfort', 35)]\n"
          ]
        }
      ],
      "source": [
        "# Predict on new audio snippets\n",
        "predictions = []\n",
        "\n",
        "folder_path = 'samples/'\n",
        "\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".wav\"):\n",
        "        audiofile, sr = librosa.load(os.path.join(folder_path, filename))\n",
        "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=20)\n",
        "        fingerprint_flat = fingerprint.reshape(-1)  # Flatten the MFCC features\n",
        "        # Pad or truncate features to match the number of features used for training\n",
        "        if len(fingerprint_flat) < 2000:\n",
        "            fingerprint_flat = np.pad(fingerprint_flat, (0, 2000 - len(fingerprint_flat)))\n",
        "        elif len(fingerprint_flat) > 2000:\n",
        "            fingerprint_flat = fingerprint_flat[:2000]\n",
        "        prediction = model.predict([fingerprint_flat])  # Reshape to match expected input format\n",
        "        predictions.append(prediction[0])\n",
        "\n",
        "from collections import Counter\n",
        "data = Counter(predictions)\n",
        "print(data.most_common())  # Returns all unique items and their counts\n",
        "print(data.most_common(1))  # Returns the most common prediction\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
